{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iKly3HS7lGJ6"
      },
      "outputs": [],
      "source": [
        "# Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ycg_XMtrjK4Z"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers[torch] datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SG_Ab637lIkx"
      },
      "outputs": [],
      "source": [
        "!pip install -q bitsandbytes trl peft\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H79wqmgmlszC",
        "outputId": "6897b003-49b9-4d0b-ece6-2a6068ce9ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flash-attn in /usr/local/lib/python3.11/dist-packages (2.7.4.post1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.5.1+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fkhaIniic5M"
      },
      "source": [
        "DOCLING BASED GENERATION OF DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YHL0AF5WVSqc"
      },
      "outputs": [],
      "source": [
        "# !pip install docling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DwPpXpB1l0Gz"
      },
      "outputs": [],
      "source": [
        "# from docling.document_converter import DocumentConverter\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GUExHbmJVWXE"
      },
      "outputs": [],
      "source": [
        "# source = \"https://www.JEEnet.in/wp-content/uploads/2019/07/JEE-MODEL-QUESTIONS-Part-1.pdf\"\n",
        "# converter = DocumentConverter()\n",
        "# result = converter.convert(source)\n",
        "# print(result.document.export_to_markdown())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fW28GuiihwP"
      },
      "source": [
        "**Hugging face dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryuD4zvuYSrt",
        "outputId": "65c561d7-3844-42ed-c221-6b75169935d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"Likhi2003/linearalgebra_QA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiNSJJdUkM8Q",
        "outputId": "de79e4a9-66c5-407c-dc1f-5207a45b4e32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 178\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 45\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# remove this when done debugging\n",
        "\n",
        "dataset_dict = {\"train\": raw_datasets[\"train\"].select(range(0,int(223*.8))),\n",
        "                \"test\": raw_datasets[\"train\"].select(range(int(223*.8),223))}\n",
        "\n",
        "raw_datasets = DatasetDict(dataset_dict)\n",
        "raw_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XzzpMTpnJub"
      },
      "source": [
        "INST has questions and the other part has answer, we need to separate those"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xVJie2P4keh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246d81e7-f274-4d5e-b617-8a380c4e17fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['text'])\n",
            "{'text': '<s>[INST] Level-1: What is the matrix-vector multiplication of a 2x2 matrix A = [a11, a12] and a 1x2 vector x = [x1]? [/INST] Ax = [a11x1, a12x1] </s>'}\n"
          ]
        }
      ],
      "source": [
        "example = raw_datasets[\"train\"][0]\n",
        "print(example.keys())\n",
        "print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg2Q7m5IktJ1",
        "outputId": "9f0d388a-05a7-467c-db06-0a83d5d15344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Level-1: What is the matrix-vector multiplication of a 2x2 matrix A = [a11, a12] and a 1x2 vector x = [x1]?\n",
            "Answer: Ax = [a11x1, a12x1]\n",
            "Question: Level-1: What is the matrix-vector multiplication of a 2x2 matrix A = [a11, a12] and a 1x2 vector x = [x1]?\n",
            "Answer: Ax = [a11x1, a12x1]\n",
            "Question: Level-1: If A is an nxn matrix and x is an nx1 vector, what is the value of Ax = [Ax1, Ax2, ..., Axn]?\n",
            "Answer: Ax = x1v1 + x2v2 + ... + xnvn.\n",
            "Question: Level-1: Prove that the matrix-vector multiplication of a square matrix A = [a11, a12, ..., a1n] and a vector x = [x1, x2, ..., xn] is commutative.\n",
            "Answer: The matrix-vector multiplication of a square matrix A = [a11, a12, ..., a1n] and a vector x = [x1, x2, ..., xn] is commutative.\n",
            "Question: Level-1: If A is an nxn matrix and x is an nx2 vector, what is the value of Ax = [Ax1, Ax2, ..., Axn]?\n",
            "Answer: Ax = [Ax1, Ax2, ..., Axn] = [x1v1 + x2v2 + ... + xnvn, x1v2 + x2v3 + ... + xnv n, ..., x1v n + x2v n + ... + xnv n].\n",
            "Question: Level-1: Prove that the matrix-vector multiplication of a matrix A = [a11, a12, ..., a1n] and a vector x = [x1, x2, ..., xn] is associative.\n",
            "Answer: The matrix-vector multiplication of a matrix A = [a11, a12, ..., a1n] and a vector x = [x1, x2, ..., xn] is associative.\n",
            "Question: Level-1: Can you use the identity matrix to find the rank of a matrix? How?\n",
            "Answer: Yes, you can use the identity matrix to find the rank of a matrix. The identity matrix is a matrix that has the same dimensions as the original matrix, and all of its elements are 1. By multiplying the original matrix with the identity matrix, you can transform the original matrix into an equivalent matrix where all of the elements of the original matrix are on the diagonal. This means that the rank of the original matrix is equal to the number of non-zero elements in the diagonal of the transformed matrix.\n",
            "Question: Level-1: Suppose you have a vector b and a set of vectors v1, v2, and v3. Can you find a linear combination of these vectors that has a direction angle of 60 degrees? How do you know?\n",
            "Answer: Yes, it is possible to find a linear combination of v1, v2, and v3 that has a direction angle of 60 degrees using the dot product formula.\n",
            "Question: Level-1: What is the inverse of a matrix A if A is not invertible?\n",
            "Answer: The inverse of a matrix A if A is not invertible does not exist.\n",
            "Question: Level-1: Can a matrix have more than one inverse? Why or why not?\n",
            "Answer: No, a matrix can only have one inverse. According to Definition 10.1, if a matrix A is invertible, then there exists a matrix C such that AC = In and CA = In. This means that the inverse of A, denoted by A^-1, satisfies AA^-1 = A^-1A = In. Therefore, a matrix can only have one inverse.\n",
            "Question: Level-1: How does the inverse of a matrix A relate to the equation ax = b?\n",
            "Answer: The inverse of a matrix A relates to the equation ax = b in that the inverse of A can be used to solve the equation by multiplying both sides by A-1 and obtaining x = A-1b.\n",
            "Question: Level-1: What is the difference between the inverse of a matrix A and the inverse of a scalar a?\n",
            "Answer: The difference between the inverse of a matrix A and the inverse of a scalar a is that the inverse of a matrix A is a matrix, while the inverse of a scalar a is a scalar. In other words, the inverse of a matrix A is a linear transformation that maps the matrix A to its inverse, while the inverse of a scalar a is a scalar that multiplies the scalar a to obtain its reciprocal.\n",
            "Question: Level-1: What is the relationship between the determinant of a matrix and its inverse?\n",
            "Answer: The relationship between the determinant of a matrix and its inverse is that the determinant of a matrix is equal to the product of its cofactors, or det(A) = aj·cT, where aj is the jth row of the matrix A and c is the matrix whose entries are the cofactors of A.\n",
            "Question: Level-1: Can you use the inverse of a matrix to find the solution to a linear transformation? How?\n",
            "Answer: Yes, you can use the inverse of a matrix to find the solution to a linear transformation. Specifically, if you have a linear transformation T: V → W, where V and W are vector spaces, and a matrix A representing the transformation, then you can use the inverse of A to find the solution to T. To see why this is the case, recall that the inverse of a matrix A, denoted by A^-1, satisfies the property that AA^-1 = A^-1A = I, where I is the identity matrix. Therefore, if you have a vector x in the domain of T, you can find the solution to T(x) by computing x = A^-1T(x).\n",
            "Question: Level-1: How does the inverse of a matrix relate to the concept of linear independence?\n",
            "Answer: The inverse of a matrix does not directly relate to the concept of linear independence. The inverse of a matrix is a tool used to solve systems of linear equations, while linear independence is a property of vectors or sets of vectors that determines whether they can be expressed as a linear combination of each other. The two concepts are distinct and operate in different contexts.\n",
            "Question: Level-1: What is the determinant of a 2x2 matrix [a11, a12] [a21, a22]?\n",
            "Answer: The determinant of a 2x2 matrix [a11, a12] [a21, a22] is a11a22 - a12a21.\n",
            "Question: Level-1: Can you find the determinant of a 3x3 matrix [a11, a12, a13] [a21, a22, a23] [a31, a32, a33]?\n",
            "Answer: The determinant of the 3x3 matrix [a11, a12, a13] [a21, a22, a23] [a31, a32, a33] is 77.\n",
            "Question: Level-1: What is the relationship between the determinant of a 2x2 matrix and its inverse?\n",
            "Answer: The relationship between the determinant of a 2x2 matrix and its inverse is that the determinant of a matrix is equal to the determinant of its inverse. In other words, det(A) = det(A^-1).\n",
            "Question: Level-1: What is the difference between the determinant of a 2x2 matrix and its trace?\n",
            "Answer: The difference between the determinant of a 2x2 matrix and its trace is that the determinant is a scalar value that can be used to determine the invertibility of a matrix, while the trace is a scalar value that represents the sum of the diagonal elements of a matrix. In other words, the determinant provides information about the solvability of a system of linear equations, while the trace provides information about the size of a matrix.\n",
            "Question: Level-1: What is the relationship between the determinant of a matrix and its rank?\n",
            "Answer: The relationship between the determinant of a matrix and its rank is that the determinant of a matrix is zero if and only if the rank of the matrix is less than or equal to 1. In other words, if the determinant of a matrix is non-zero, then the rank of the matrix is greater than 1.\n",
            "Question: Level-1: Can you use the determinant of a matrix to find the solution to a system of linear equations? How?\n",
            "Answer: Yes, you can use the determinant of a matrix to find the solution to a system of linear equations. The determinant of a matrix can be used to determine the solvability of a system of linear equations, and it can also be used to find the solution to the system.\n",
            "Question: Level-1: What is the difference between a matrix with a determinant of 0 and a matrix with a determinant of 1?\n",
            "Answer: The difference between a matrix with a determinant of 0 and a matrix with a determinant of 1 is that a matrix with a determinant of 0 has no inverse, while a matrix with a determinant of 1 has an inverse.\n",
            "Question: Level-2: If A = [a11, a12; a21, a22], and x = [x1, x2], then what is the value of Ax?\n",
            "Answer: Ax = x1a11 + x2a12 + x1a21 + x2a22.\n",
            "Question: Level-2: Consider the linear system $Ax = b$, where $A$ is an $n \\times n$ matrix and $b$ is an $n \\times 1$ vector. Can you use the identity matrix to solve this system of linear equations? How?\n",
            "Answer: No, you cannot use the identity matrix to solve the linear system $Ax = b$.\n",
            "Question: Level-2: If v1 = (1, 2, 3), v2 = (4, 5, 6), and v3 = (7, 8, 9), find the linear combination of these vectors that is closest to the vector (2, 3, 4).\n",
            "Answer: Yes, b2 is a linear combination of v1 and v2.\n",
            "Question: Level-2: Given the vectors v1 = (1, 0, 0), v2 = (0, 1, 0), and v3 = (0, 0, 1), find the linear combination of these vectors that is closest to the vector (1, 1, 1).\n",
            "Answer: The closest linear combination of v1, v2, and v3 to (1, 1, 1) is b = (1, 1, 0).\n",
            "Question: Level-2: If b = (2, 3, 4) and v1 = (1, 0, 0), v2 = (0, 1, 0), and v3 = (0, 0, 1), find the linear combination of these vectors that is closest to b.\n",
            "Answer: Yes, b2 is a linear combination of v1, v2. The closest linear combination of v1 and v2 to b2 is (1, 1, 0).\n",
            "Question: Level-2: A system of linear equations consists of 3 equations and 4 unknowns. How many possible solutions can it have?\n",
            "Answer: A system of linear equations with 3 equations and 4 unknowns can have a maximum of 3 possible solutions.\n",
            "Question: Level-2: A matrix represents a system of linear equations. If the matrix is invertible, what can you say about the solvability of the system?\n",
            "Answer: If a matrix represents a system of linear equations, and the matrix is invertible, then the system is solvable.\n",
            "Question: Level-2: How does the inverse of a matrix relate to the determinant of a matrix? Can you explain this relationship in simple terms?\n",
            "Answer: The inverse of a matrix relates to the determinant of a matrix through the formula det(A^-1) = 1 / det(A). In simple terms, the determinant of a matrix is a value that can be used to determine if a matrix has an inverse, and the inverse of a matrix can be found by multiplying the determinant of the matrix by an appropriate value.\n",
            "Question: Level-2: What is the determinant of a 2x2 matrix [a 11, a 12]?\n",
            "Answer: The determinant of a 2x2 matrix [a 11, a 12] is a11a22 - a12a21.\n",
            "Question: Level-2: Given a 2x2 matrix [a 11, a 12], find the equation of the circle that passes through the center [0, 0] and has radius |a 11|.\n",
            "Answer: (x - 0)^2 + (y - 0)^2 = |a 11|^2\n",
            "Question: Level-2: Given an eigen value λ and an eigen vector v of a matrix A, prove that the eigen vector v is unique.\n",
            "Answer: The distributive property of matrix multiplication, (A - λI)v = 0, implies that if v is an eigenvector of A with eigenvalue λ, then v must be in the null space of A - λI, v ∈ Null(A - λI).\n",
            "Question: Level-3: If A = [a11, a12; a21, a22], and x = [x1, x2], then what is the value of Ax = [a11x1 + a12x2, a21x1 + a22x2]?\n",
            "Answer: Ax = [a11x1 + a12x2, a21x1 + a22x2].\n",
            "Question: Level-3: Let A and B be matrices of sizes m x n and n x p, respectively. If x is a vector of size m, then what is the value of (AB)x = [AB]x?\n",
            "Answer: The value of (AB)x = [AB]x is a vector of size n, where n is the number of columns in the matrix B.\n",
            "Question: Level-3: If A is an m x n matrix and x is an n x 1 vector, then what is the value of Ax = [a11x, a12x, ..., a1nx]?\n",
            "Answer: The value of Ax = [a11x, a12x, ..., a1nx] is equal to x1Av1 + x2Av2 + ... + xnAvn.\n",
            "Question: Level-3: Let A be an m x n matrix and x is an m x 1 vector. If y is an n x 1 vector, then what is the value of Ay = [ay1, ay2, ..., ayn]?\n",
            "Answer: Ay = [ay1, ay2, ..., ayn] = A(x) where x is an m x 1 vector.\n",
            "Question: Level-3: Let $v1 = (1, 2, 3)$, $v2 = (4, 5, 6)$, and $v3 = (7, 8, 9)$. Find the linear combination of these vectors that is closest to the vector $(2, 3, 4)$.\n",
            "Answer: The closest linear combination of $v1$, $v2$, and $v3$ to the vector $(2, 3, 4)$ is $b1 = (1, 2, 3) + (1, 0, 0) = (2, 3, 4)$.\n",
            "Question: Level-3: Let $A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 3 \\end{bmatrix}$ and $b = (2, 3)$. Find the linear combination of the vectors $v1 = (1, 0)$ and $v2 = (0, 1)$ that solves the system $Ax = b$.\n",
            "Answer: $x = (1, 1)$.\n",
            "Question: Level-3: Let $v1 = (a, b)$, $v2 = (c, d)$, and $v3 = (e, f)$. Find the linear combination of these vectors that is proportional to the vector $(a + c, b + d)$.\n",
            "Answer: Yes, there exists scalars x1, x2, x3 such that x1v1 + x2v2 + x3v3 = b.\n",
            "Question: Level-3: Let $v1 = (1, 0)$, $v2 = (0, 1)$, and $v3 = (1, 1)$. Find the linear combination of these vectors that is closest to the vector $(1, 1)$.\n",
            "Answer: The closest linear combination of $v1$, $v2$, and $v3$ to the vector $(1, 1)$ is $v1 + v2 + v3 = (2, 1)$.\n",
            "Question: Level-3: A matrix represents a system of linear equations. If the matrix is invertible, what can you say about the system? Can you use the inverse of the matrix to solve the system?\n",
            "Answer: if the matrix is invertible, it can have only one inverse. Therefore, if you use the inverse of the matrix to solve the system of linear equations, you will get only one solution.\n",
            "Question: Level-3: Prove that if A is an invertible matrix and b is a non-zero vector, then there exists a unique vector x such that Ax = b.\n",
            "Answer: If A is an invertible matrix and b is a non-zero vector, then there exists a unique vector x such that Ax = b. This can be proven by using the fact that if A is invertible, then A-1 exists, and multiplying both sides of the equation Ax = b by A-1, we get A-1Ax = A-1b, which implies that x = A-1b. Therefore, the unique solution to the equation Ax = b is x = A-1b.\n",
            "Question: Level-3: Let A and B be invertible matrices. Can you find the inverse of the matrix A + B using the equation (A + B)^-1 = A^-1 + B^-1?\n",
            "Answer: Yes, you can find the inverse of the matrix A + B using the equation (A + B)^-1 = A^-1 + B^-1.\n",
            "Question: Level-3: Let A be an invertible matrix and b is a non-zero vector. Can you find the inverse of the matrix A using the equation A^Tb = b?\n",
            "Answer: Yes, you can find the inverse of an invertible matrix A using the equation A^Tb = b.\n",
            "Question: Level-3: Consider the matrix A = [a11, a12; a21, a22]. If a11 = a22 = 2 and a12 = a21 = 1, can you find a 2x2 submatrix of A that has a determinant of 4? How do you know this submatrix exists?\n",
            "Answer: Yes, you can find a 2x2 submatrix of A that has a determinant of 4. The submatrix is [a11, a12; a21, a22]. The determinant of this submatrix is 4, because a11 = 2, a12 = 1, a21 = 2, and a22 = 1.\n",
            "Question: Level-3: If A and B are 2x2 matrices, can you find a matrix C such that AC = B and C has a determinant of 1? How do you know that C exists?\n",
            "Answer: Yes, there exists a matrix C such that AC = B and C has a determinant of 1.\n",
            "Question: Level-3: Given a matrix A and an eigen value λ, find the corresponding eigen vector v of A.\n",
            "Answer: To find the corresponding eigenvector v of a matrix A with an eigenvalue λ, you can solve the equation Av = λv.\n",
            "Question: Level-3: Given a matrix A and an eigen value λ, find the dimension of the null space of A - λI.\n",
            "Answer: The dimension of the null space of A - λI is 8.\n",
            "Question: Level-4: Let A and B be m × n matrices. Prove that (AB)x = AxBx for any m × 1 vector x.\n",
            "Answer: (AB)x = AxBx for any m × 1 vector x.\n",
            "Question: Level-4: Let $v1 = (1, 0)$, $v2 = (0, 1)$, and $v3 = (1, 1)$. Find the linear combination of these vectors that is closest to the vector $(1, 1)$.\n",
            "Answer: The closest linear combination of $v1$, $v2$, and $v3$ to the vector $(1, 1)$ is $x_1 v_1 + x_2 v_2 = (1, 1)$.\n",
            "Question: Level-4: Let $v1 = (1, 0)$, $v2 = (0, 1)$, and $v3 = (2, 0)$. Find the linear combination of these vectors that is closest to the vector $(1, 1)$.\n",
            "Answer: The closest linear combination of $v1$, $v2$, and $v3$ to $(1, 1)$ is $v1 + v2$.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "seq = raw_datasets[\"train\"][\"text\"]\n",
        "\n",
        "# Regular expression to capture the INST part and the rest of the string\n",
        "for sequence in seq:\n",
        "    match = re.match(r\"<s>\\[INST\\](.*?)\\[/INST\\](.*?)</s>\", sequence)\n",
        "    if match:\n",
        "        inst_part = match.group(1).strip()\n",
        "        rest_part = match.group(2).strip()\n",
        "        print(\"Question:\", inst_part)\n",
        "        print(\"Answer:\", rest_part)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPpB06oisTZD",
        "outputId": "dc24d51b-6f60-420f-ad0f-be9bc7c52da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `LLM` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `LLM`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8VK1y5kQpeoz"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,  # Can be bf16 if your GPU supports it\n",
        "    device_map=\"auto\",  # Auto-assign devices (CPU/GPU)\n",
        "    low_cpu_mem_usage=True,  # Prevents RAM overflow\n",
        "    attn_implementation=\"flash_attention_2\",  # Reduces memory usage\n",
        "    load_in_4bit=True,  # Uses 4-bit quantization to reduce memory\n",
        ")\n",
        "\n",
        "\n",
        "# set pad_token_id equal to the eos_token_id if not set\n",
        "if tokenizer.pad_token_id is None:\n",
        "  tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Set reasonable default for models without max length\n",
        "if tokenizer.model_max_length > 100_000:\n",
        "  tokenizer.model_max_length = 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Cy7_ZPvGvg3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030ff8fd-8ae2-484c-e619-056f96132ba9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 178\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 45\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "raw_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Rgao9nYkvg2t"
      },
      "outputs": [],
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# specify how to quantize the model\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "device_map = {\"\": torch.cuda.current_device()} if torch.cuda.is_available() else None\n",
        "\n",
        "model_kwargs = dict(\n",
        "    attn_implementation=\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n",
        "    torch_dtype=\"auto\",\n",
        "    use_cache=False, # set to False as we're going to use gradient checkpointing\n",
        "    device_map=device_map,\n",
        "    quantization_config=quantization_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxiDXJEGwH2N"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from peft import LoraConfig\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "# path where the Trainer will save its checkpoints and logs\n",
        "output_dir = 'data/zephyr-7b-sft-lora'\n",
        "\n",
        "# based on config\n",
        "training_args = TrainingArguments(\n",
        "    fp16=True, # specify bf16=True instead when training on GPUs that support bf16\n",
        "    do_eval=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    gradient_accumulation_steps=128,\n",
        "    gradient_checkpointing=True,\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "    learning_rate=2.0e-05,\n",
        "    log_level=\"info\",\n",
        "    logging_steps=5,\n",
        "    logging_strategy=\"steps\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    max_steps=-1,\n",
        "    num_train_epochs=1,\n",
        "    output_dir=output_dir,\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_eval_batch_size=1, # originally set to 8\n",
        "    per_device_train_batch_size=1, # originally set to 8\n",
        "    # push_to_hub=True,\n",
        "    # hub_model_id=\"zephyr-7b-sft-lora\",\n",
        "    # hub_strategy=\"every_save\",\n",
        "    # report_to=\"tensorboard\",\n",
        "    save_strategy=\"no\",\n",
        "    save_total_limit=None,\n",
        "    seed=42,\n",
        "    # packing=False,\n",
        "    # dataset_text_field=\"text\",\n",
        "    # max_seq_length=tokenizer.model_max_length,\n",
        "\n",
        ")\n",
        "\n",
        "# based on config\n",
        "peft_config = LoraConfig(\n",
        "        r=16,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        # model_init_kwargs=model_kwargs,\n",
        "        args=training_args,\n",
        "        train_dataset=raw_datasets[\"train\"],\n",
        "        eval_dataset=raw_datasets[\"test\"],\n",
        "        tokenizer=tokenizer,\n",
        "        peft_config=peft_config,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0W2ZdBEwLWn"
      },
      "outputs": [],
      "source": [
        "train_result = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsuypFvCwLVl"
      },
      "outputs": [],
      "source": [
        "metrics = train_result.metrics\n",
        "max_train_samples = training_args.max_train_samples if training_args.max_train_samples is not None else len(raw_datasets[\"train\"])\n",
        "metrics[\"train_samples\"] = min(max_train_samples, len(raw_datasets[\"train\"]))\n",
        "trainer.log_metrics(\"train\", metrics)\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "trainer.save_state()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "model = AutoModelForCausalLM.from_pretrained(output_dir, load_in_4bit=True, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "hTqq_kQE0WOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Generate 10 linear algebra questions\"}\n",
        "]\n",
        "\n",
        "# prepare the messages for the model\n",
        "input_ids = tokenizer.apply_chat_template(messages, truncation=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# inference\n",
        "outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=256,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95\n",
        ")\n",
        "print(tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])"
      ],
      "metadata": {
        "id": "ehxIHS570YX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6LXiVh3B0bqL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}